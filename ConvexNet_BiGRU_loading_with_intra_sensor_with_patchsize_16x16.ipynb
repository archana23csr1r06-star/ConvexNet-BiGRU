{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9046d233-39f3-401d-81fc-6d69c6b8b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, LSTM, BatchNormalization, Input, Reshape, TimeDistributed, GlobalAveragePooling1D\n",
    ")\n",
    "#from tensorflow.keras.applications import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfddcfe-a1a3-43cc-bb88-9d590463c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "PATCH_SIZE = (16, 16) \n",
    "PATCHES_PER_IMAGE = (IMAGE_SIZE[0] // PATCH_SIZE[0]) ** 2\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502cf2a-79fe-4ea5-a825-25797ba2a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess fingerprint images\n",
    "def load_images_with_labels(live_paths, fake_paths):\n",
    "    images, labels = [], []\n",
    "    for paths, label in zip([live_paths, fake_paths], [0, 1]):\n",
    "        for path in paths:\n",
    "            for subdir, _, files in os.walk(path):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.png', '.jpeg', '.jpg', '.tif', '.bmp')):\n",
    "                        img_path = os.path.join(subdir, file)\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img_resized = cv2.resize(img, IMAGE_SIZE)\n",
    "                            images.append(img_resized)\n",
    "                            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1bb79-2724-4c67-a359-c6b4a8aa5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract patches from images\n",
    "def extract_patches(images):\n",
    "    patchified = []\n",
    "    for img in images:\n",
    "        patches = []\n",
    "        for i in range(0, IMAGE_SIZE[0], PATCH_SIZE[0]):\n",
    "            for j in range(0, IMAGE_SIZE[1], PATCH_SIZE[1]):\n",
    "                patch = img[i:i+PATCH_SIZE[0], j:j+PATCH_SIZE[1], :]\n",
    "                patches.append(patch)\n",
    "        patchified.append(patches)\n",
    "    return np.array(patchified)\n",
    "\n",
    "# \n",
    "from tensorflow.keras.applications import ConvNeXtTiny\n",
    "from tensorflow.keras.layers import Bidirectional, GRU\n",
    "\n",
    "def build_convnext_bigru(input_shape_patch=(56, 56, 3), patch_count=PATCHES_PER_IMAGE):\n",
    "    patch_input = Input(shape=(patch_count,) + input_shape_patch)\n",
    "    \n",
    "    # Feature extractor with ConvNeXt-Tiny\n",
    "    base_model = ConvNeXtTiny(include_top=False, weights='imagenet', pooling='avg', input_shape=input_shape_patch)\n",
    "    base_model.trainable = False  # Freeze to use as feature extractor\n",
    "\n",
    "    # Apply ConvNeXt to each patch\n",
    "    x = TimeDistributed(base_model)(patch_input)\n",
    "    \n",
    "    # BiGRU \n",
    "    x = Bidirectional(GRU(128, return_sequences=True))(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    return Model(inputs=patch_input, outputs=output)\n",
    "# Provide your actual dataset paths here\n",
    "live_paths = [\n",
    "\n",
    "    \"/livedetfinerprin/Fingerprint/2013/Fingerprint/Testing/SwipeTest/SwipeTest/Live\",\n",
    "    \"/livedetfinerprin/Fingerprint/2013/Fingerprint/Training/SwipeTest/SwipeTest/Live\"\n",
    "]\n",
    "fake_paths = [\n",
    "\"/livedetfinerprin/Fingerprint/2013/Fingerprint/Testing/SwipeTest/SwipeTest/Spoof/BodyDouble\",\n",
    "    \"/livedetfinerprin/Fingerprint/2013/Fingerprint/Testing/SwipeTest/SwipeTest/Spoof/Latex\",\n",
    "    \"/livedetfinerprin/Fingerprint/2013/Fingerprint/Testing/SwipeTest/SwipeTest/Spoof/PlayDoh\",\n",
    "    \"/livedetfinerprin/Fingerprint/2013/Fingerprint/Testing/SwipeTest/SwipeTest/Spoof/WoodGlue\",\n",
    "\n",
    "\"/livedetfinerprin/Fingerprint/2013/Fingerprint/Training/SwipeTest/SwipeTest/Spoof/BodyDouble\",\n",
    "    \"/livedetfinerprin/Fingerprint/2013/Fingerprint/Training/SwipeTest/SwipeTest/Spoof/Latex\",\n",
    "    \"/livedetfinerprin/Fingerprint/2013/Fingerprint/Training/SwipeTest/SwipeTest/Spoof/PlayDoh\",\n",
    "    \"/livedetfinerprin/Fingerprint/2013/Fingerprint/Training/SwipeTest/SwipeTest/Spoof/WoodGlue\",    \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8654b-39b3-40a2-ba83-5ddeea80dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "images, labels = load_images_with_labels(live_paths, fake_paths)\n",
    "images = preprocess_input(images.astype('float32'))\n",
    "patches = extract_patches(images)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    patches, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Build and train model\n",
    "model = build_convnext_bigru()\n",
    "model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888715b0-6afd-4e9f-8c40-bfceca9985f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stop, lr_reduce]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678421da-e341-417d-a560-317ff2e33c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and evaluation\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Live\", \"Fake\"]))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76261bab-9bf8-4a21-8618-01607419db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\\nAUC: {auc:.4f}\\nF1: {f1:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\")\n",
    "# Updated Plotting Functions\n",
    "def plot_training_accuracy(history):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', color='#ff7f0e', linestyle='--', linewidth=2, marker='o')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='#1f77b4', linestyle='-', linewidth=2, marker='s')\n",
    "    plt.title('Training and Validation Accuracy', fontsize=24, fontweight='bold')\n",
    "    plt.xlabel('Epochs', fontsize=22, fontweight='bold')\n",
    "    plt.ylabel('Accuracy', fontsize=22, fontweight='bold')\n",
    "    plt.xticks(fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc='lower right', fontsize=20)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b430b3-233e-4c6f-8ac3-ee3e3160ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_loss(history):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(history.history['loss'], label='Train Loss', color='#d62728', linestyle='--', linewidth=2, marker='x')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', color='#9467bd', linestyle='-', linewidth=2, marker='d')\n",
    "    plt.title('Training and Validation Loss', fontsize=24, fontweight='bold')\n",
    "    plt.xlabel('Epochs', fontsize=22, fontweight='bold')\n",
    "    plt.ylabel('Loss', fontsize=22, fontweight='bold')\n",
    "    plt.xticks(fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc='upper right', fontsize=20)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612911a1-e67e-443a-bd5f-6415fe383b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_f1(precision, recall, f1):\n",
    "    metrics = ['Precision', 'Recall', 'F1 Score']\n",
    "    values = [precision, recall, f1]\n",
    "    colors = ['#2ca02c', '#ff9896', '#98df8a']  # Greenish tones for contrast\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.bar(metrics, values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "    plt.title('Precision, Recall, and F1 Score', fontsize=24, fontweight='bold')\n",
    "    plt.xlabel('Metrics', fontsize=22, fontweight='bold')\n",
    "    plt.ylabel('Scores', fontsize=22, fontweight='bold')\n",
    "    plt.xticks(fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96acc4-b374-45d5-a7ae-2950aa136089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_percentage(y_test, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix_percentage = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix_percentage, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, annot_kws={\"size\": 16})\n",
    "    plt.title('Confusion Matrix (Percentage)', fontsize=24, fontweight='bold')\n",
    "    plt.xlabel('Predicted Class', fontsize=22, fontweight='bold')\n",
    "    plt.ylabel('True Class', fontsize=22, fontweight='bold')\n",
    "    plt.xticks(fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2797e-4139-4f2a-9125-04e36cf422be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_pred_prob):\n",
    "    from sklearn.metrics import roc_curve, auc  # Ensure proper import for auc\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc_score_value = auc(fpr, tpr)  # Renamed variable to avoid conflict\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score_value:.4f}', linewidth=2, color='#17becf', linestyle='-')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', linewidth=1, alpha=0.7)\n",
    "    plt.title('ROC Curve', fontsize=24, fontweight='bold')\n",
    "    plt.xlabel('False Positive Rate', fontsize=22, fontweight='bold')\n",
    "    plt.ylabel('True Positive Rate', fontsize=22, fontweight='bold')\n",
    "    plt.legend(loc='lower right', fontsize=20)\n",
    "    plt.xticks(fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7328795-895c-42e4-a3a7-673a555ee53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Results\n",
    "plot_training_accuracy(history)\n",
    "plot_training_loss(history)\n",
    "plot_precision_recall_f1(precision, recall, f1)\n",
    "plot_confusion_matrix_percentage(y_test, y_pred)\n",
    "plot_roc_curve(y_test, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306048ba-6d7a-4d0f-a58d-d188eb592cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7853d73c-8d16-49e5-bc55-9a18510e43a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
